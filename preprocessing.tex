\chapter {Preprocessing}

The data from the tweets was cleaned by removing the tweets that were in different languages as well as the ones that were retweeted, which is equivalent of re-publishing the same tweet from a different user. 

Unique URLs were first extracted from the 16,000 or so URLs in the data. Next, data from these unique URLs was extracted and then preprocessed. For the articles obtained from URLs, photos and video links for example, from Instagram and Youtube needed to be removed. For this, the data cleaning was achieved by removing articles by limiting word length of the extracted text to about 150 words. This ensured the removal of photos, videos, advertisements, incorrectly extracted articles from the data.  After this preprocessing, the number of useful articles reduced to 3066 from 6003.

\section {Tagging articles}

For the first trial for tagging, a sample set of 100 articles were tagged by two people. The tags used in the preliminary tags were : ‘evaluative’ vs ‘descriptive’ and ‘traditional’ vs ‘nontraditional’ news sources. ‘Evaluative’ text is a more opinionated text, that is more subjective. This text will be expected to take a certain object or event, analyze it,  and form an opinion about it. ‘Descriptive’ text is non-evaluative, containing for example a narration of an event or an explanation about a certain object or event. A ‘mixed’ category was also added to accommodate some in-between articles. ‘Traditional’ texts are the ones published by established news houses and a more formal form of discourse. ‘Nontraditional’ texts are a more colloquial and informal way of writing text - longer, with less fact verification and a more explanatory and narrative kind of feel to it. These also include shorter web articles that are somewhere between a blog post and a news article. They are not as free of rules as a blog post, but are not in the style of a rigid news article.

The title, the text and origin of the articles were considered while tagging them. The tagging itself was subjective based on the opinion of the tagger about what category the article fell into. It was observed that there were a few judgement calls, specially between the evaluative/descriptive/mixed tags.

Correlation was calculated between the two different sets of tags to check if the opinions about the articles were unanimous. The Cohen’s kappa value was used for the purpose. Overall, the kappa value turned out to be 0.69. However, it was found that there was high correlation between the taggers for traditional vs. nontraditional texts with a kappa value of 0.88, and lesser correlation for evaluative/descriptive/mixed texts, 0.13. This seems to suggest an absence of an exact definition of evaluative versus descriptive texts. 

However, the Cohen’s kappa value shows that traditional vs nontraditional tags correlate well between taggers. Upon analysis of the ones that differed, the differences of opinions between the taggers could be resolved. This suggests that, this axis of description for the article as traditional vs nontraditional can be tagged accordingly.

\section {Current description of data}

The data currently consists of all tweets alongwith all the information of the tweet itself, such as the text of the tweet, links to articles if any, hashtags, and so on. The article links from these tweets are stored as a separate file, with information about the articles themselves, along with some preprocessed data. This includes the URL itself and the text extracted from the article, as well as some extracted information such as sentence boundaries, POS tags for tokens, parse trees and dependency trees. This processing of the text was done using the CoreNLP toolkit developed at Stanford (Manning et al., 2014 \cite{manning2014stanford})

Tweets are linked to URLs through another file. A URL could have been tweeted through multiple tweets, all the ids of these tweets are linked to the same URL. 
