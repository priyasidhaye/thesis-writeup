\chapter{Data Extraction and Preprocessing}
\label{chap:data}

This chapter discusses the need for a new dataset of indicative tweets and linked articles, the decision to use Twitter data for the study, and the process of data collection for the thesis. The process of data collection includes the methods used for extracting data from Twitter, and the preprocessing done on the data to prepare it for analysis. 


\section{The Need for a New Dataset}

As mentioned earlier, there have been numerous studies that used data from the public Twitter feeds. However, only a few of the datasets in those studies focused on tweets in conjunction with articles linked to these tweets. One such dataset was collected by \cite{lloret2013towards}, but it only contains 200 English tweet-article pairs. \cite{wei2014utilizing} also constructed a dataset that contains both tweets and articles linked to by the tweets, but this data only deals with news text, and does not contain the variety of topics and genres we wanted in the data. These datasets did not give us the ability to explore relationships between amount of extraction in tweets, genres and other stylistic factors such as formality, as described in \chapref{chap:background}. We therefore chose to build our own dataset. The following section describes the extraction, cleaning and other preprocessing steps that we preformed on the data.

\section{Extracting Data}
\label{sec:extractingdata}



Data was extracted from Twitter using the Twitter REST API using 51 `hashtags', which are handles with which tweets are tagged. These hashtags were chosen from a range of topics including pop culture,  international summit meetings discussing political issues, lawsuits and trials, social issues and health care issues. All these hashtags were `trending' (being tweeted about at a high rate) at the time of extraction of the data. To get a broader sample, the data was extracted over the course of 15 days in November, 2014, rather than on a single point in time. From this set of possible topics, we selected hashtags such that there would be broad representation in terms of various stylistic properties of text (e.g. formality and subjectivity), different genres, and a variety of sources of articles. Different kinds of sources would include established news outlets, blogs, and individuals. All the search terms used are shown in \tabref{tab:searchterms}, and have been classified into different genres for the purpose of ease of reading.

\begin{table}[!t]
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Science} \& \textbf{Technology}                                                                                                                               & \textbf{Entertainment}                                                                                                                                                                              & \textbf{Events}                                                                                                                                                                         & \textbf{Miscellaneous}                                                                                                                                                                                                                                                 \\ \hline
\begin{tabular}[c]{@{}l@{}}\#android\\ \#cometlanding\\ \#lollipop\\ \#lollipopupdate\\  \#mangalayan\\ \#nexus6\\  \#philae\\ \#rosetta\  \end{tabular} & \begin{tabular}[c]{@{}l@{}}\#1989\\  \#BBCSyriaWars\\ \#betterstarwarstitles\\  \#harrypotter\\ \#interstellar\\ \#johnoliver\\ \#moneyball \\ \#montythepenguin\\  \#TaylorSwift\\  \#theforceawakens\\   \#winteriscoming\end{tabular} & \begin{tabular}[c]{@{}l@{}}\#bahamas \\ \#buffalosnow\\  \#haiyan\\  \#lestweforget\\  \#MarysvilleShooting\\ \#memorialday\\ \#ottawashootings \\ \#snowstorm  \end{tabular} & \begin{tabular}[c]{@{}l@{}}\#1wtc\\ \#abercrombieandfitch\\ \#annefrank\\ \#beenrapedneverreported\\   \#KevinVickers\\  \#mentalhealth\\ \#netneutrality\\ \#pointergate\\ \#RobertONeill\\  \end{tabular} \\ \hline
\textbf{Politics}                                                                                                                                            & \textbf{International}                                                                                                                                                                                    & \textbf{Sports}                                                                                                                                                                         & \textbf{Legal}                                                                                                                                                                                                                                                        \\ \hline
\begin{tabular}[c]{@{}l@{}} \#apec\\ \#apec2014\\ \#cdnpoli\\ \#G20\\ \#GOP\\  \end{tabular}                                                             & \begin{tabular}[c]{@{}l@{}}\#berlinwall\\ \#canadachinatradedeal\\ \#ebola\\ \#erdogan\\ \#obamacare\\\#putin \\ \#syria\\   \end{tabular}                                                                          & \begin{tabular}[c]{@{}l@{}}\#ausvssa\\ \#nycmarathon\\ \#playingitmyway\\  \end{tabular}                                                                             & \begin{tabular}[c]{@{}l@{}} \#ghomeshi\\ \#oscarpistorius\\ \end{tabular}                                                                                                                                                                                         \\ \hline
\end{tabular}
\captionof{table}{Hashtags used for extraction, grouped into various categories.}
\label{tab:searchterms}
\end{table}

% For example, searches related to politics would be more formal, while those related to films would be informal, and would also have a lot more opinion pieces about them.

We extracted 30,621 tweets, of which more than half, or 16,349, contained URLs to an external news article, photo on a photo sharing site, or video. The hashtags were chosen to maximise the number of articles linked to by the tweets. Many topics that were chosen were being tweeted about by news agencies and other popular news sources.

Before extracting the URLs, The data from the tweets was cleaned by removing the tweets that were not in English. We also removed retweets; i.e., re-publications of a tweet by a different user.

We deduplicated the 16,349 extracted URLs into 6,003 unique addresses, then extracted and preprocessed their contents. The \texttt{newspaper} package\footnote{https://pypi.python.org/pypi/newspaper} was used to extract article text and the title from the web page. Since we are interested in text articles that can serve as the source text for summarization algorithms, we needed to remove photos and video links such as those from Instagram and YouTube. To do so, we removed those links that contained fewer than a threshold of 150 words. This preprocessing reduced the number of useful articles from 6,003 to 3,066. Further tweet-article pairs where the text of the tweets was identical were removed and the number of remaining unique tweet-article pairs was 2471. It should be noted that this extraction tool is not very effective at extracting titles from text.

\begin{table}[!t]
\centering
\begin{tabular}{|p{0.1\linewidth}|p{0.8\linewidth}|}
\hline
\textbf{Tweet} & \#RiggsReport: \#CA as the \#ElectionNight exception. Voters rewarded \#GOP nationally, but not in the \#GoldenState. http://t.co/K542wvSNVz \\ \hline
\textbf{Title} & The Riggs Report: California as the Election Night exception                                                                                 \\ \hline
\textbf{Text}  & When the dust settled on Election Night last week...                                                                                         \\ \hline
\end{tabular}
\captionof{table}{Example of a tweet, title of the article and the text.}
\label{tab:ex1}
\end{table}

The final version of the data consists of tweets along with other information about the tweet: links to articles, hashtags, time of publication and other details provided by the Twitter API, which were not relevant to our analyses. We also retained the linked article text and preprocessed it using the CoreNLP toolkit developed by  \cite{manning2014stanford}. This includes the URL itself and the text extracted from the article, as well as some extracted information such as sentence boundaries, POS tags for tokens, parse trees and dependency trees. These annotations are used later during our analysis in \chapref{chap:analysis}. \tabref{tab:ex1} shows an example of an entry in the dataset. A URL could have been tweeted through multiple tweets: i.e.,  the \texttt{id}s of these tweets are linked to the same URL.

We will discuss the analyses performed on this dataset in \chapref{chap:analysis}.